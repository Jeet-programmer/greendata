{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvRhWzTcT-1d",
        "outputId": "4fbffedf-acdb-4d37-bad4-224754ff7bf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: transformers 4.27.0.dev0\n",
            "Uninstalling transformers-4.27.0.dev0:\n",
            "  Successfully uninstalled transformers-4.27.0.dev0\n",
            "\u001b[33m  WARNING: Did not find branch or tag 'c3dc391', assuming revision or ref.\u001b[0m\u001b[33m\n",
            "\u001b[0m  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q datasets loralib sentencepiece\n",
        "!pip uninstall transformers -y\n",
        "!pip install -q git+https://github.com/zphang/transformers@c3dc391\n",
        "!pip -q install git+https://github.com/huggingface/peft.git\n",
        "!pip -q install bitsandbytes\n",
        "!pip install flask pyngrok -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607,
          "referenced_widgets": [
            "dcfab0c7f27547aa934987c7e97d79e6",
            "358968135a9d43969120b9ddb85377f2",
            "96ec7e8e1ee544409bb0e194a32d7263",
            "49fdf3f8fbd341a3bf0526226ec913f5",
            "650abf3815ef4b7aadf62a6c65e44e2d",
            "a43a72eef8344e2db2e604d1ed5abc30",
            "fac7d4b408a74b77933231da07f4aea0",
            "6352600fdc2d491db57774e4c0d5a9a3",
            "228f6d18dce54fd0bf3e6b1174c3a109",
            "146e22d608924ab0be3cde8bbd88e94e",
            "fe217a6bcff74fc7bb553ca2135e358d"
          ]
        },
        "id": "LOKBI0P6T_oC",
        "outputId": "7f6840f5-f752-4067-841b-7797057d7989"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please run\n",
            "\n",
            "python -m bitsandbytes\n",
            "\n",
            " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "bin /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so\n",
            "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
            "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so.11.0\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
            "CUDA SETUP: Detected CUDA version 118\n",
            "CUDA SETUP: Loading binary /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: /usr/lib64-nvidia did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('8013'), PosixPath('//172.28.0.1'), PosixPath('http')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/gpu-t4-s-16n6otizq3nss --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true'), PosixPath('--logtostderr --listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/env/python')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//ipykernel.pylab.backend_inline')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0'), PosixPath('/usr/local/cuda/lib64/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
            "Either way, this might cause trouble in the future:\n",
            "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
            "  warn(msg)\n",
            "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dcfab0c7f27547aa934987c7e97d79e6"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from peft import PeftModel\n",
        "from transformers import LLaMATokenizer, LLaMAForCausalLM, GenerationConfig\n",
        "import textwrap\n",
        "\n",
        "\n",
        "\n",
        "tokenizer = LLaMATokenizer.from_pretrained(\"decapoda-research/llama-7b-hf\")\n",
        "\n",
        "model = LLaMAForCausalLM.from_pretrained(\n",
        "    \"decapoda-research/llama-7b-hf\",\n",
        "    load_in_8bit=True,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "model = PeftModel.from_pretrained(model, \"samwit/alpaca7B-lora\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJDKuG9KUCqa"
      },
      "outputs": [],
      "source": [
        "\n",
        "def alpaca_talk(text):\n",
        "    prompt = f'''Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{text} \n",
        "\n",
        "### Response:\n",
        "'''\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        prompt,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    input_ids = inputs[\"input_ids\"].cuda()\n",
        "\n",
        "    generation_config = GenerationConfig(\n",
        "        temperature=0.6,\n",
        "        top_p=0.95,\n",
        "        repetition_penalty=1.2,\n",
        "    )\n",
        "    print(\"Generating...\")\n",
        "    generation_output = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        generation_config=generation_config,\n",
        "        return_dict_in_generate=True,\n",
        "        output_scores=True,\n",
        "        max_new_tokens=256,\n",
        "    )\n",
        "    ans = []\n",
        "    for s in generation_output.sequences:\n",
        "        # print(tokenizer.decode(s))\n",
        "        ans.append(tokenizer.decode(s))\n",
        "    return ans[0].split(\"### Response:\")[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vE-UcseQUFui"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaKVbR4vDo7B"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "BASE_URL = \"http://api.openweathermap.org/data/2.5/weather?\"\n",
        "API_KEY = \"******\"\n",
        "CITY = \"New York\"\n",
        "\n",
        "\n",
        "url = BASE_URL + \"appid=\" + API_KEY + \"&q=\" + CITY\n",
        "\n",
        "#function to convert kelvin to celcius\n",
        "def k2C(N):\n",
        "  c=N-273\n",
        "  return c\n",
        "\n",
        "def Weatherget(city):\n",
        "  url = BASE_URL + \"appid=\" + API_KEY + \"&q=\" + city\n",
        "  response = requests. get(url).json()\n",
        "# print(response)\n",
        "\n",
        "  #getting the temp\n",
        "  temp_kelvin = response['main']['temp']\n",
        "  temp_celcius = k2C(temp_kelvin)\n",
        "  max_temp = k2C(response['main']['temp_max'])\n",
        "  min_temp = k2C(response['main']['temp_min'])\n",
        "\n",
        "  #getting pressure and humidity\n",
        "  pressure = response['main']['pressure']\n",
        "  humidity= response['main']['humidity']\n",
        "\n",
        "  #getting weather type\n",
        "  weathertype = response['weather'][0]['main']\n",
        "  weatherdesc = response['weather'][0]['description']\n",
        "\n",
        "  #if rain occurs the give me the rain mm\n",
        "  if weathertype == \"rain\":\n",
        "    rainvol = response['rain']['1h']\n",
        "  else:\n",
        "    rainvol = 0\n",
        "  \n",
        "\n",
        "  #getting wind value\n",
        "  windspeed = response['wind']['speed']\n",
        "  wind_degree = response['wind']['deg']\n",
        "\n",
        "  #cloud data\n",
        "  cloud = response['clouds']['all']\n",
        "\n",
        "  W= \"No Warnings\"\n",
        "\n",
        "  #warnings\n",
        "  if rainvol >= 100:\n",
        "    W= \"Flood incoming\"\n",
        "  elif rainvol >= 50:\n",
        "    W= \"The heavy rain fall may damage the crops\"\n",
        "  elif windspeed >= 33.33:\n",
        "    W =\"Cyclone incoming\"\n",
        "  elif max_temp >= 39:\n",
        "    W = \"There is a heate wave going in the region\"\n",
        "  elif min_temp <= 10:\n",
        "    W= \"There is a cold wave going in the region\"\n",
        "\n",
        "  A= f\"City= {city}\\n Temp(kelvin)= {temp_kelvin} \\n Temp(Celcius) = {temp_celcius} \\n Warnings = {W} \\n Pressure = {pressure}hPa \\n Humidity = {humidity}% \\n Weather = {weathertype} \\n Weather Description = {weatherdesc} \\n Rain Volume = {rainvol}mm \\n Wind Speed = {windspeed}m/s \\n Wind Direction in degree = {wind_degree} \\n Clouds = {cloud}%\"\n",
        "  return A\n",
        "  # print(A)\n",
        "# Weatherget(CITY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TGvILKFUMl5"
      },
      "outputs": [],
      "source": [
        "# Crops = \"Rice\"\n",
        "\n",
        "# City = \"New York\"\n",
        "# A= Weatherget(City)\n",
        "# prompt = f\"I am a farmer and I am cultivating {Crops} Give some suggestions in th following weather conditions {A}\"\n",
        "# Message= alpaca_talk(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iaJfgiz7bH3Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "767d6041-f03e-4212-c050-c25daa10542f"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting vonage\n",
            "  Downloading vonage-3.4.0-py2.py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: pytz>=2018.5 in /usr/local/lib/python3.10/dist-packages (from vonage) (2022.7.1)\n",
            "Requirement already satisfied: pydantic>=1.10.2 in /usr/local/lib/python3.10/dist-packages (from vonage) (1.10.7)\n",
            "Collecting PyJWT[crypto]>=1.6.4\n",
            "  Downloading PyJWT-2.6.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: requests>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from vonage) (2.27.1)\n",
            "Collecting Deprecated\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.2->vonage) (4.5.0)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from PyJWT[crypto]>=1.6.4->vonage) (40.0.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.4.2->vonage) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.4.2->vonage) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.4.2->vonage) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.4.2->vonage) (1.26.15)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated->vonage) (1.14.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.4.0->PyJWT[crypto]>=1.6.4->vonage) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.4.0->PyJWT[crypto]>=1.6.4->vonage) (2.21)\n",
            "Installing collected packages: PyJWT, Deprecated, vonage\n",
            "Successfully installed Deprecated-1.2.13 PyJWT-2.6.0 vonage-3.4.0\n"
          ]
        }
      ],
      "source": [
        "# !pip install dotenv\n",
        "!pip install vonage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8y15VnE9fj2W"
      },
      "outputs": [],
      "source": [
        "# print (Message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIyLys0Eao21"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# from os.path import join, dirname\n",
        "# from dotenv import load_dotenv\n",
        "import vonage\n",
        "# dotenv_path = join(dirname(__file__), \"../.env\")\n",
        "# load_dotenv(dotenv_path)\n",
        "\n",
        "client = vonage.Client(key=\"233854f3\", secret=\"ja80Tjf0NpZCsy56\")\n",
        "sms = vonage.Sms(client)# sms = vonage.Sms(client)\n",
        "\n",
        "NEXMO_API_KEY = \"****\"\n",
        "NEXMO_API_SECRET = \"***\"\n",
        "TO_NUMBER = \"919832103941\"\n",
        "NEXMO_BRAND_NAME = 'Green Data'\n",
        "\n",
        "# import nexmo\n",
        "\n",
        "# client = nexmo.Client(key=NEXMO_API_KEY, secret=NEXMO_API_SECRET)\n",
        "\n",
        "responseData = sms.send_message(\n",
        "    {\n",
        "        \"from\": NEXMO_BRAND_NAME,\n",
        "        \"to\": TO_NUMBER,\n",
        "        \"text\": Message,\n",
        "    }\n",
        ")\n",
        "\n",
        "if responseData[\"messages\"][0][\"status\"] == \"0\":\n",
        "    print(\"Message sent successfully.\")\n",
        "else:\n",
        "    print(f\"Message failed with error: {responseData['messages'][0]['error-text']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuXXEjYdhFmK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66fd6615-fe7b-4e1e-819a-52d7e7d5384d"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting twilio\n",
            "  Downloading twilio-8.2.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from twilio) (2.27.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from twilio) (2022.7.1)\n",
            "Requirement already satisfied: aiohttp>=3.8.4 in /usr/local/lib/python3.10/dist-packages (from twilio) (3.8.4)\n",
            "Collecting aiohttp-retry>=2.8.3\n",
            "  Downloading aiohttp_retry-2.8.3-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: PyJWT<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from twilio) (2.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->twilio) (2.0.12)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->twilio) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->twilio) (23.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->twilio) (1.3.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->twilio) (1.9.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->twilio) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->twilio) (6.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->twilio) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->twilio) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->twilio) (1.26.15)\n",
            "Installing collected packages: aiohttp-retry, twilio\n",
            "Successfully installed aiohttp-retry-2.8.3 twilio-8.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install twilio\n",
        "# !pip install pyautogui "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDlNnIHsV76D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dfbd41f-322e-4419-c533-5f3d01d2ab2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating...\n",
            "{'Name': 'Jeet', 'Weather': 'City= New York\\n Temp(kelvin)= 291.77 \\n Temp(Celcius) = 18.769999999999982 \\n Warnings = No Warnings \\n Pressure = 1009hPa \\n Humidity = 67% \\n Weather = Clouds \\n Weather Description = overcast clouds \\n Rain Volume = 0mm \\n Wind Speed = 1.79m/s \\n Wind Direction in degree = 282 \\n Clouds = 100%', 'Response': '\\nSuggestions for growing rice under these conditions include using drip irrigation, planting early to avoid high temperatures, and choosing varieties suited to cooler climates such as short-grain or medium grains'}\n"
          ]
        }
      ],
      "source": [
        "def report(name,phone,city,pin,crop):\n",
        "  Z= Weatherget(CITY)\n",
        "  Crops = \"Rice\"\n",
        "  prompt = f\"I am a farmer and I am cultivating {crop} Give some suggestions in th following weather conditions {Z}\"\n",
        "  Message= alpaca_talk(prompt)\n",
        "  D = {\"Name\": name, \"Weather\": Z, \"Response\": Message}\n",
        "  return D\n",
        "# City = \"New York\"\n",
        "# A= Weatherget(City)\n",
        "print(report(\"Jeet\",12333115,\"Kolkata\",7000105,\"Rice\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRHaw2_UvhNQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5942a64-6dc5-4fa3-f4e6-592297279bbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "'FLASK_ENV' is deprecated and will not be used in Flask 2.3. Use 'FLASK_DEBUG' instead.\n",
            "WARNING:pyngrok.process.ngrok:t=2023-05-08T03:09:32+0000 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * ngrok tunnel \"https://8dca-34-143-181-58.ngrok-free.app\" -> \"http://127.0.0.1:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "'FLASK_ENV' is deprecated and will not be used in Flask 2.3. Use 'FLASK_DEBUG' instead.\n",
            "'FLASK_ENV' is deprecated and will not be used in Flask 2.3. Use 'FLASK_DEBUG' instead.\n",
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import threading\n",
        "from flask import Flask, request, render_template, jsonify, render_template_string\n",
        "from pyngrok import ngrok, conf\n",
        "import requests\n",
        "import json\n",
        "\n",
        "\n",
        "\n",
        "conf.get_default().auth_token = \"2OJVuhSh4cupkKJmquQgWg1LZvm_248RTG6VbDzKhyed5ECdk\"\n",
        "\n",
        "os.environ[\"FLASK_ENV\"] = \"development\"\n",
        "\n",
        "app = Flask(__name__)\n",
        "port = 5000\n",
        "\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print(\" * ngrok tunnel \\\"{}\\\" -> \\\"http://127.0.0.1:{}\\\"\".format(public_url, port))\n",
        "\n",
        "\n",
        "app.config[\"BASE_URL\"] = public_url\n",
        "app.config[\"FLASK_DEBUG\"] = 1\n",
        "\n",
        "@app.route('/')\n",
        "def hello_world():\n",
        "    return 'Hi, World!'\n",
        "\n",
        "@app.route('/report/')\n",
        "def report(n=None):\n",
        "  name = request.args\n",
        "  C = name[\"city\"]\n",
        "  Crops = name[\"crop\"]\n",
        "  Z= Weatherget(C)\n",
        "  N= name[\"name\"]\n",
        "  Ph = name[\"ph\"]\n",
        "  # Crops = \"Rice\"\n",
        "  prompt = f\"I am a farmer and I am cultivating {Crops} Give some suggestions in th following weather conditions {Z}\"\n",
        "  Message= alpaca_talk(prompt)\n",
        "  D = {\"Name\": name, \"Weather\": Z, \"Response\": Message}\n",
        "  return D\n",
        "\n",
        "threading.Thread(target=app.run, kwargs={\"use_reloader\": False}).start()    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5864MvM2yQIt"
      },
      "outputs": [],
      "source": [
        "!pkill ngrok\n",
        "!pkill python"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dcfab0c7f27547aa934987c7e97d79e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_358968135a9d43969120b9ddb85377f2",
              "IPY_MODEL_96ec7e8e1ee544409bb0e194a32d7263",
              "IPY_MODEL_49fdf3f8fbd341a3bf0526226ec913f5"
            ],
            "layout": "IPY_MODEL_650abf3815ef4b7aadf62a6c65e44e2d"
          }
        },
        "358968135a9d43969120b9ddb85377f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a43a72eef8344e2db2e604d1ed5abc30",
            "placeholder": "​",
            "style": "IPY_MODEL_fac7d4b408a74b77933231da07f4aea0",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "96ec7e8e1ee544409bb0e194a32d7263": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6352600fdc2d491db57774e4c0d5a9a3",
            "max": 33,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_228f6d18dce54fd0bf3e6b1174c3a109",
            "value": 33
          }
        },
        "49fdf3f8fbd341a3bf0526226ec913f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_146e22d608924ab0be3cde8bbd88e94e",
            "placeholder": "​",
            "style": "IPY_MODEL_fe217a6bcff74fc7bb553ca2135e358d",
            "value": " 33/33 [01:06&lt;00:00,  2.09s/it]"
          }
        },
        "650abf3815ef4b7aadf62a6c65e44e2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a43a72eef8344e2db2e604d1ed5abc30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fac7d4b408a74b77933231da07f4aea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6352600fdc2d491db57774e4c0d5a9a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "228f6d18dce54fd0bf3e6b1174c3a109": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "146e22d608924ab0be3cde8bbd88e94e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe217a6bcff74fc7bb553ca2135e358d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}